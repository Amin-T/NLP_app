{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This file is to run and test the NERmodel_trainer function.\n",
    "\n",
    "Run the below cells to create a training data from a sample text data and train a custom NER."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Import libraries\n",
    "from NERmodel_trainer import build_TrainData, train_costume_NER\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import requests\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Read the sample text data\n",
    "with open('sample_train_text.txt', 'r') as f:\n",
    "    train_text = f.read()\n",
    "\n",
    "# Download the zip file contents of US-GAAP taxonomy in binary format\n",
    "url = 'https://www.fasb.org/cs/BlobServer?blobkey=id&blobnocache=true&blobwhere=1175836290847&blobheader=application%2Fzip&blobheadername2=Content-Length&blobheadername1=Content-Disposition&blobheadervalue2=9013838&blobheadervalue1=attachment%3B+filename%3DUS_GAAP_Taxonomy_2021.zip&blobcol=urldata&blobtable=MungoBlobs'\n",
    "r = requests.get(url)\n",
    "\n",
    "# Read the content of the zip file as a pandas dataframe\n",
    "with ZipFile(BytesIO(r.content), 'r') as zipObj:\n",
    "    file = zipObj.open(zipObj.namelist()[0])\n",
    "    tax_df = pd.read_excel(file)\n",
    "\n",
    "# Remove depricated taxonomy items\n",
    "tax_df = tax_df[tax_df['deprecatedDate'].isna()]\n",
    "\n",
    "# Create a list of labels as entity labels for training the NER\n",
    "pattern = '\\[.*\\]'\n",
    "tax_df['label'] = tax_df['label'].str.replace(pattern, '').tolist()\n",
    "Labels = tax_df[['name', 'label']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Call the function to initiate the training data builder\n",
    "data_builder = build_TrainData(train_text=train_text, model='en_core_web_md')\n",
    "\n",
    "# Create the training data\n",
    "train_data = data_builder.TrainData(Labels)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/amin/NLP_app/venv/lib/python3.8/site-packages/spaczz/matcher/tokenmatcher.py:115: UserWarning: [W036] The component 'matcher' does not have any patterns defined.\n",
      "  matches = matcher(doc)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   0 sentences processed;    0 training samples saved.\n",
      "  50 sentences processed;    5 training samples saved.\n",
      " 100 sentences processed;    6 training samples saved.\n",
      " 150 sentences processed;   12 training samples saved.\n",
      " 200 sentences processed;   13 training samples saved.\n",
      " 250 sentences processed;   16 training samples saved.\n",
      " 300 sentences processed;   20 training samples saved.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Train the spaCy nlp model on the created training dataset\n",
    "trained_NER = train_costume_NER(train_data=train_data, model='en_core_web_md', \n",
    "                                n_iter=10, output_dir='Trained_NER')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded en_core_web_md model.\n",
      "Iter: 1 - losses: {'ner': 71.91662378197704}\n",
      "Iter: 2 - losses: {'ner': 45.49556114048783}\n",
      "Iter: 3 - losses: {'ner': 34.997234170665706}\n",
      "Iter: 4 - losses: {'ner': 32.64720423617304}\n",
      "Iter: 5 - losses: {'ner': 32.05719015190242}\n",
      "Iter: 6 - losses: {'ner': 30.778474935068896}\n",
      "Iter: 7 - losses: {'ner': 27.555528637208788}\n",
      "Iter: 8 - losses: {'ner': 25.212736804005942}\n",
      "Iter: 9 - losses: {'ner': 25.778193587854584}\n",
      "Iter: 10 - losses: {'ner': 23.435328318111267}\n",
      "Saved model to  Trained_NER\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "6e9fa4d45349a95c7accd434e28d3060f9ae889cdba79af1a8980af7c00019f2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}